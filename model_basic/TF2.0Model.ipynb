{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-dev20191002'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division, absolute_import, unicode_literals\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting perameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 256\n",
    "im_height = 256\n",
    "path_train = r'D:\\wall_segmentation\\basicModel.001\\unfiltered\\input\\train'\n",
    "#path_test = os.path.join( os.getcwd(), 'input',  'test')\n",
    "classes = ['dark_dense_distribution', 'Elongated_nuclei','light_dense_istribution','light_distribution',\n",
    "           'No_nuclei_with_uniform_texture','No_nuclei_with_unstructured','Red_texture',  'Round_nuclei','Mixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\wall_segmentation\\\\basicModel.001\\\\unfiltered\\\\input\\\\train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = np.array([\n",
    "    [128,0,0],\n",
    "    [128,8,0],\n",
    "    [0,0,255],\n",
    "    [0,128,0],\n",
    "    [255,255,0],\n",
    "    [255,105,180],\n",
    "    [255,0,0],\n",
    "    [255,165,0],\n",
    "    [128,128,128]], dtype=np.uint8)\n",
    "palette = np.divide(palette, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50196078, 0.        , 0.        ],\n",
       "       [0.50196078, 0.03137255, 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.50196078, 0.        ],\n",
       "       [1.        , 1.        , 0.        ],\n",
       "       [1.        , 0.41176471, 0.70588235],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.64705882, 0.        ],\n",
       "       [0.50196078, 0.50196078, 0.50196078]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all([[[True, True, True]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode( mask, palette):\n",
    "        \"\"\"\n",
    "        Converts mask to a one-hot encoding specified by the semantic map.\n",
    "        \"\"\"\n",
    "        one_hot_map = []\n",
    "        for colour in palette:\n",
    "            class_map = tf.reduce_all(tf.equal(mask, colour), axis=-1)\n",
    "            one_hot_map.append(class_map)\n",
    "        one_hot_map = tf.stack(one_hot_map, axis=-1)\n",
    "        one_hot_map = tf.cast(one_hot_map, tf.float32)\n",
    "        \n",
    "        return one_hot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, palette, train=True):\n",
    "    ids = next(os.walk(path + \"\\images\"))[2]\n",
    "    mask_ids = next(os.walk(path + '\\masks'))[2]\n",
    "    X = np.zeros((len(ids), im_height, im_width, 3), dtype=np.float32)\n",
    "    if train:\n",
    "        y = np.zeros((len(mask_ids), im_height, im_width, palette.shape[0]), dtype=np.float32)\n",
    "        masks = np.zeros((len(mask_ids), im_height, im_width, 3), dtype=np.float32)\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "        img = imread(path + '/images/'+ id_)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (im_height, im_width, 3), mode='constant', preserve_range=True)\n",
    "        X[n] = x_img/255\n",
    "        \n",
    "    for n, id_ in tqdm_notebook(enumerate(mask_ids), total=len(mask_ids)):\n",
    "        if train:\n",
    "            mask = img_to_array(imread(path + '/masks/' + id_ ))\n",
    "            mask = (resize(mask, (im_height, im_width, 3), mode='constant', preserve_range=True))\n",
    "        if train:\n",
    "            y[n] = one_hot_encode(mask/255, palette)\n",
    "            masks[n] = mask/255\n",
    "    print('Done!')\n",
    "    if train:\n",
    "        return X, y , masks\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing images ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4278b1d3f7be4ce9a000a831363982d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00291cd1005499ebdaf9cbc7f8b0729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "X, y, masks = get_data(path_train, train=True, palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567, 256, 256, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(ix):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    ax[0].imshow(X_train[ix])\n",
    "    ax[0].set_title('Image')\n",
    "\n",
    "    ax[1].imshow(y_train[ix])\n",
    "    ax[1].set_title('mask');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (256, 256, 9) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-97c71e319c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplot_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-435ee7a0abda>\u001b[0m in \u001b[0;36mplot_img\u001b[1;34m(ix)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1601\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5671\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 690\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (256, 256, 9) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    ix = random.randint(0, len(X_train))\n",
    "    plot_img(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    \n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(9, (1, 1), activation='softmax') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    y_true = tf.round(tf.reshape(y_true, [-1]))\n",
    "    y_pred = tf.round(tf.reshape(y_pred, [-1]))\n",
    "    \n",
    "    isct = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    return 2 * isct / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred))\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 16) 448         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 16) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   18496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 128)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 256)  295168      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 128)  295040      activation_9[0][0]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   73792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 64, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 64)   73792       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 32) 18464       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 128, 64) 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 32) 18464       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 32) 128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 32) 9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 16) 4624        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256, 256, 32) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 16) 4624        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 16) 64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256, 256, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 16) 2320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 9)  153         activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,164,729\n",
      "Trainable params: 2,161,785\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((im_height, im_width, 3), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[dice_coef, 'acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [\n",
    "    EarlyStopping( patience=10, verbose=1),\n",
    "    ReduceLROnPlateau( factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-unet-basic_tf2.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "    TensorBoard(logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 408 samples, validate on 86 samples\n",
      "Epoch 1/100\n",
      "384/408 [===========================>..] - ETA: 6:35 - loss: 0.6200 - dice_coef: 0.0036 - acc: 0.465 - ETA: 5:17 - loss: 0.7190 - dice_coef: 0.0018 - acc: 0.420 - ETA: 4:31 - loss: 0.6416 - dice_coef: 0.0012 - acc: 0.409 - ETA: 3:36 - loss: 0.6404 - dice_coef: 9.0289e-04 - acc: 0.391 - ETA: 2:58 - loss: 0.6204 - dice_coef: 7.2371e-04 - acc: 0.383 - ETA: 2:28 - loss: 0.6089 - dice_coef: 6.9642e-04 - acc: 0.381 - ETA: 2:02 - loss: 0.5989 - dice_coef: 7.1147e-04 - acc: 0.379 - ETA: 1:38 - loss: 0.6251 - dice_coef: 9.1925e-04 - acc: 0.367 - ETA: 1:15 - loss: 0.6025 - dice_coef: 0.0017 - acc: 0.3697    - ETA: 54s - loss: 0.5880 - dice_coef: 0.0024 - acc: 0.369 - ETA: 34s - loss: 0.5704 - dice_coef: 0.0035 - acc: 0.37 - ETA: 14s - loss: 0.5621 - dice_coef: 0.0045 - acc: 0.3713\n",
      "Epoch 00001: val_loss improved from inf to 0.40558, saving model to model-unet-basic_tf2.h5\n",
      "408/408 [==============================] - 252s 618ms/sample - loss: 0.5498 - dice_coef: 0.0072 - acc: 0.3728 - val_loss: 0.4056 - val_dice_coef: 0.0000e+00 - val_acc: 0.4541\n",
      "Epoch 2/100\n",
      "384/408 [===========================>..] - ETA: 3:23 - loss: 0.5528 - dice_coef: 0.0179 - acc: 0.360 - ETA: 3:04 - loss: 0.4304 - dice_coef: 0.0111 - acc: 0.380 - ETA: 2:45 - loss: 0.4543 - dice_coef: 0.0137 - acc: 0.378 - ETA: 2:30 - loss: 0.4384 - dice_coef: 0.0141 - acc: 0.387 - ETA: 2:12 - loss: 0.4218 - dice_coef: 0.0201 - acc: 0.392 - ETA: 1:55 - loss: 0.4429 - dice_coef: 0.0193 - acc: 0.397 - ETA: 1:38 - loss: 0.4163 - dice_coef: 0.0235 - acc: 0.400 - ETA: 1:21 - loss: 0.4109 - dice_coef: 0.0241 - acc: 0.399 - ETA: 1:04 - loss: 0.4281 - dice_coef: 0.0244 - acc: 0.401 - ETA: 47s - loss: 0.4365 - dice_coef: 0.0238 - acc: 0.400 - ETA: 30s - loss: 0.4382 - dice_coef: 0.0227 - acc: 0.40 - ETA: 12s - loss: 0.4383 - dice_coef: 0.0230 - acc: 0.4079\n",
      "Epoch 00002: val_loss did not improve from 0.40558\n",
      "408/408 [==============================] - 225s 552ms/sample - loss: 0.4300 - dice_coef: 0.0230 - acc: 0.4070 - val_loss: 0.5035 - val_dice_coef: 0.0058 - val_acc: 0.2771\n",
      "Epoch 3/100\n",
      "384/408 [===========================>..] - ETA: 3:12 - loss: 0.4048 - dice_coef: 0.0153 - acc: 0.412 - ETA: 3:10 - loss: 0.2905 - dice_coef: 0.0261 - acc: 0.412 - ETA: 2:51 - loss: 0.3365 - dice_coef: 0.0255 - acc: 0.414 - ETA: 2:33 - loss: 0.3748 - dice_coef: 0.0219 - acc: 0.416 - ETA: 2:18 - loss: 0.3560 - dice_coef: 0.0217 - acc: 0.416 - ETA: 2:00 - loss: 0.3875 - dice_coef: 0.0209 - acc: 0.426 - ETA: 1:42 - loss: 0.3697 - dice_coef: 0.0227 - acc: 0.429 - ETA: 1:25 - loss: 0.3651 - dice_coef: 0.0272 - acc: 0.432 - ETA: 1:07 - loss: 0.3634 - dice_coef: 0.0276 - acc: 0.433 - ETA: 49s - loss: 0.3711 - dice_coef: 0.0285 - acc: 0.435 - ETA: 31s - loss: 0.3778 - dice_coef: 0.0287 - acc: 0.43 - ETA: 13s - loss: 0.3838 - dice_coef: 0.0303 - acc: 0.4372\n",
      "Epoch 00003: val_loss did not improve from 0.40558\n",
      "408/408 [==============================] - 235s 577ms/sample - loss: 0.3785 - dice_coef: 0.0389 - acc: 0.4403 - val_loss: 0.5415 - val_dice_coef: 0.0618 - val_acc: 0.1924\n",
      "Epoch 4/100\n",
      "384/408 [===========================>..] - ETA: 3:21 - loss: 0.3946 - dice_coef: 0.1694 - acc: 0.458 - ETA: 3:10 - loss: 0.3125 - dice_coef: 0.2739 - acc: 0.467 - ETA: 2:51 - loss: 0.3077 - dice_coef: 0.2782 - acc: 0.471 - ETA: 2:33 - loss: 0.3070 - dice_coef: 0.2958 - acc: 0.480 - ETA: 2:17 - loss: 0.3027 - dice_coef: 0.2994 - acc: 0.484 - ETA: 1:59 - loss: 0.2959 - dice_coef: 0.2990 - acc: 0.485 - ETA: 1:41 - loss: 0.3050 - dice_coef: 0.2909 - acc: 0.488 - ETA: 1:24 - loss: 0.2965 - dice_coef: 0.3037 - acc: 0.488 - ETA: 1:07 - loss: 0.2901 - dice_coef: 0.3013 - acc: 0.485 - ETA: 49s - loss: 0.2867 - dice_coef: 0.3051 - acc: 0.489 - ETA: 31s - loss: 0.2821 - dice_coef: 0.3170 - acc: 0.48 - ETA: 13s - loss: 0.2979 - dice_coef: 0.3161 - acc: 0.4877\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.40558\n",
      "408/408 [==============================] - 236s 579ms/sample - loss: 0.2956 - dice_coef: 0.3289 - acc: 0.4893 - val_loss: 0.9813 - val_dice_coef: 0.1971 - val_acc: 0.1328\n",
      "Epoch 5/100\n",
      "384/408 [===========================>..] - ETA: 3:24 - loss: 0.3884 - dice_coef: 0.2768 - acc: 0.470 - ETA: 3:13 - loss: 0.3596 - dice_coef: 0.3778 - acc: 0.501 - ETA: 2:53 - loss: 0.3630 - dice_coef: 0.3968 - acc: 0.496 - ETA: 2:34 - loss: 0.3205 - dice_coef: 0.4548 - acc: 0.496 - ETA: 2:17 - loss: 0.3097 - dice_coef: 0.4665 - acc: 0.486 - ETA: 2:00 - loss: 0.2912 - dice_coef: 0.5043 - acc: 0.490 - ETA: 1:42 - loss: 0.2840 - dice_coef: 0.4753 - acc: 0.479 - ETA: 1:24 - loss: 0.2757 - dice_coef: 0.4744 - acc: 0.480 - ETA: 1:06 - loss: 0.2753 - dice_coef: 0.4701 - acc: 0.482 - ETA: 48s - loss: 0.2736 - dice_coef: 0.4708 - acc: 0.483 - ETA: 31s - loss: 0.2754 - dice_coef: 0.4643 - acc: 0.48 - ETA: 13s - loss: 0.2746 - dice_coef: 0.4666 - acc: 0.4856\n",
      "Epoch 00005: val_loss improved from 0.40558 to 0.40051, saving model to model-unet-basic_tf2.h5\n",
      "408/408 [==============================] - 236s 579ms/sample - loss: 0.2671 - dice_coef: 0.4816 - acc: 0.4846 - val_loss: 0.4005 - val_dice_coef: 0.0000e+00 - val_acc: 0.7356\n",
      "Epoch 6/100\n",
      "384/408 [===========================>..] - ETA: 3:35 - loss: 0.1744 - dice_coef: 0.4243 - acc: 0.429 - ETA: 3:19 - loss: 0.1870 - dice_coef: 0.4834 - acc: 0.446 - ETA: 2:58 - loss: 0.2064 - dice_coef: 0.5097 - acc: 0.461 - ETA: 2:38 - loss: 0.2254 - dice_coef: 0.4722 - acc: 0.456 - ETA: 2:21 - loss: 0.2273 - dice_coef: 0.4708 - acc: 0.456 - ETA: 2:03 - loss: 0.2340 - dice_coef: 0.4600 - acc: 0.460 - ETA: 1:44 - loss: 0.2375 - dice_coef: 0.4573 - acc: 0.462 - ETA: 1:26 - loss: 0.2476 - dice_coef: 0.4601 - acc: 0.464 - ETA: 1:07 - loss: 0.2582 - dice_coef: 0.4529 - acc: 0.473 - ETA: 49s - loss: 0.2676 - dice_coef: 0.4471 - acc: 0.479 - ETA: 31s - loss: 0.2623 - dice_coef: 0.4561 - acc: 0.48 - ETA: 13s - loss: 0.2587 - dice_coef: 0.4469 - acc: 0.4823\n",
      "Epoch 00006: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 239s 587ms/sample - loss: 0.2659 - dice_coef: 0.4395 - acc: 0.4849 - val_loss: 0.4554 - val_dice_coef: 0.0000e+00 - val_acc: 0.2292\n",
      "Epoch 7/100\n",
      "384/408 [===========================>..] - ETA: 3:26 - loss: 0.2766 - dice_coef: 0.3995 - acc: 0.493 - ETA: 3:15 - loss: 0.2563 - dice_coef: 0.4326 - acc: 0.485 - ETA: 2:55 - loss: 0.2368 - dice_coef: 0.4911 - acc: 0.485 - ETA: 2:37 - loss: 0.2718 - dice_coef: 0.4709 - acc: 0.485 - ETA: 2:18 - loss: 0.2604 - dice_coef: 0.4899 - acc: 0.482 - ETA: 2:01 - loss: 0.2665 - dice_coef: 0.4813 - acc: 0.477 - ETA: 1:43 - loss: 0.2688 - dice_coef: 0.4673 - acc: 0.479 - ETA: 1:25 - loss: 0.2567 - dice_coef: 0.4993 - acc: 0.485 - ETA: 1:07 - loss: 0.2604 - dice_coef: 0.4979 - acc: 0.490 - ETA: 49s - loss: 0.2581 - dice_coef: 0.4966 - acc: 0.491 - ETA: 31s - loss: 0.2589 - dice_coef: 0.4957 - acc: 0.49 - ETA: 13s - loss: 0.2538 - dice_coef: 0.5039 - acc: 0.4927\n",
      "Epoch 00007: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 242s 594ms/sample - loss: 0.2448 - dice_coef: 0.5189 - acc: 0.4902 - val_loss: 0.5024 - val_dice_coef: 0.0000e+00 - val_acc: 0.3582\n",
      "Epoch 8/100\n",
      "384/408 [===========================>..] - ETA: 3:42 - loss: 0.1431 - dice_coef: 0.6756 - acc: 0.461 - ETA: 3:23 - loss: 0.1346 - dice_coef: 0.7120 - acc: 0.479 - ETA: 2:59 - loss: 0.1703 - dice_coef: 0.6736 - acc: 0.497 - ETA: 2:39 - loss: 0.2027 - dice_coef: 0.6173 - acc: 0.503 - ETA: 2:21 - loss: 0.2113 - dice_coef: 0.6008 - acc: 0.505 - ETA: 2:03 - loss: 0.2178 - dice_coef: 0.5646 - acc: 0.500 - ETA: 1:44 - loss: 0.2203 - dice_coef: 0.5614 - acc: 0.498 - ETA: 1:25 - loss: 0.2190 - dice_coef: 0.5739 - acc: 0.498 - ETA: 1:07 - loss: 0.2283 - dice_coef: 0.5551 - acc: 0.495 - ETA: 49s - loss: 0.2241 - dice_coef: 0.5601 - acc: 0.492 - ETA: 31s - loss: 0.2227 - dice_coef: 0.5576 - acc: 0.49 - ETA: 13s - loss: 0.2246 - dice_coef: 0.5575 - acc: 0.4953\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 240s 589ms/sample - loss: 0.2293 - dice_coef: 0.5516 - acc: 0.4951 - val_loss: 0.5101 - val_dice_coef: 0.0000e+00 - val_acc: 0.4206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "384/408 [===========================>..] - ETA: 3:26 - loss: 0.2652 - dice_coef: 0.4825 - acc: 0.466 - ETA: 3:15 - loss: 0.2903 - dice_coef: 0.4700 - acc: 0.506 - ETA: 2:56 - loss: 0.2361 - dice_coef: 0.5333 - acc: 0.495 - ETA: 2:37 - loss: 0.2374 - dice_coef: 0.5191 - acc: 0.506 - ETA: 2:20 - loss: 0.2514 - dice_coef: 0.5008 - acc: 0.493 - ETA: 2:00 - loss: 0.2615 - dice_coef: 0.4829 - acc: 0.501 - ETA: 1:43 - loss: 0.2549 - dice_coef: 0.5049 - acc: 0.499 - ETA: 1:25 - loss: 0.2514 - dice_coef: 0.5055 - acc: 0.495 - ETA: 1:07 - loss: 0.2442 - dice_coef: 0.5117 - acc: 0.491 - ETA: 49s - loss: 0.2523 - dice_coef: 0.5047 - acc: 0.494 - ETA: 31s - loss: 0.2400 - dice_coef: 0.5143 - acc: 0.49 - ETA: 13s - loss: 0.2406 - dice_coef: 0.5225 - acc: 0.4926\n",
      "Epoch 00009: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 239s 585ms/sample - loss: 0.2396 - dice_coef: 0.5329 - acc: 0.4933 - val_loss: 0.5119 - val_dice_coef: 0.0000e+00 - val_acc: 0.4374\n",
      "Epoch 10/100\n",
      "384/408 [===========================>..] - ETA: 3:28 - loss: 0.1379 - dice_coef: 0.6553 - acc: 0.473 - ETA: 3:17 - loss: 0.2233 - dice_coef: 0.5759 - acc: 0.482 - ETA: 2:56 - loss: 0.2027 - dice_coef: 0.5748 - acc: 0.472 - ETA: 2:37 - loss: 0.2478 - dice_coef: 0.5156 - acc: 0.487 - ETA: 2:19 - loss: 0.2362 - dice_coef: 0.5473 - acc: 0.484 - ETA: 2:02 - loss: 0.2467 - dice_coef: 0.5383 - acc: 0.487 - ETA: 1:43 - loss: 0.2714 - dice_coef: 0.5123 - acc: 0.497 - ETA: 1:25 - loss: 0.2592 - dice_coef: 0.5250 - acc: 0.492 - ETA: 1:07 - loss: 0.2474 - dice_coef: 0.5425 - acc: 0.489 - ETA: 49s - loss: 0.2379 - dice_coef: 0.5546 - acc: 0.487 - ETA: 31s - loss: 0.2367 - dice_coef: 0.5483 - acc: 0.48 - ETA: 13s - loss: 0.2342 - dice_coef: 0.5573 - acc: 0.4894\n",
      "Epoch 00010: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 238s 584ms/sample - loss: 0.2365 - dice_coef: 0.5560 - acc: 0.4911 - val_loss: 0.5146 - val_dice_coef: 0.0000e+00 - val_acc: 0.3982\n",
      "Epoch 11/100\n",
      "384/408 [===========================>..] - ETA: 3:27 - loss: 0.1679 - dice_coef: 0.6918 - acc: 0.487 - ETA: 3:14 - loss: 0.1575 - dice_coef: 0.7014 - acc: 0.498 - ETA: 2:55 - loss: 0.2140 - dice_coef: 0.5945 - acc: 0.512 - ETA: 2:36 - loss: 0.2518 - dice_coef: 0.5329 - acc: 0.504 - ETA: 2:18 - loss: 0.2323 - dice_coef: 0.5498 - acc: 0.495 - ETA: 2:01 - loss: 0.2471 - dice_coef: 0.5320 - acc: 0.493 - ETA: 1:42 - loss: 0.2378 - dice_coef: 0.5549 - acc: 0.494 - ETA: 1:23 - loss: 0.2337 - dice_coef: 0.5649 - acc: 0.491 - ETA: 1:06 - loss: 0.2362 - dice_coef: 0.5664 - acc: 0.492 - ETA: 47s - loss: 0.2263 - dice_coef: 0.5665 - acc: 0.487 - ETA: 30s - loss: 0.2252 - dice_coef: 0.5733 - acc: 0.48 - ETA: 12s - loss: 0.2360 - dice_coef: 0.5619 - acc: 0.4920\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 227s 557ms/sample - loss: 0.2360 - dice_coef: 0.5573 - acc: 0.4919 - val_loss: 0.5148 - val_dice_coef: 0.0000e+00 - val_acc: 0.3464\n",
      "Epoch 12/100\n",
      "384/408 [===========================>..] - ETA: 3:06 - loss: 0.2065 - dice_coef: 0.5528 - acc: 0.451 - ETA: 2:50 - loss: 0.2768 - dice_coef: 0.3525 - acc: 0.416 - ETA: 2:38 - loss: 0.2585 - dice_coef: 0.4403 - acc: 0.442 - ETA: 2:21 - loss: 0.2250 - dice_coef: 0.4996 - acc: 0.451 - ETA: 2:05 - loss: 0.2307 - dice_coef: 0.4966 - acc: 0.467 - ETA: 1:49 - loss: 0.2418 - dice_coef: 0.4949 - acc: 0.476 - ETA: 1:34 - loss: 0.2461 - dice_coef: 0.4881 - acc: 0.484 - ETA: 1:20 - loss: 0.2560 - dice_coef: 0.4766 - acc: 0.489 - ETA: 1:04 - loss: 0.2542 - dice_coef: 0.4938 - acc: 0.490 - ETA: 47s - loss: 0.2545 - dice_coef: 0.4983 - acc: 0.490 - ETA: 31s - loss: 0.2508 - dice_coef: 0.5095 - acc: 0.49 - ETA: 13s - loss: 0.2523 - dice_coef: 0.5137 - acc: 0.4920\n",
      "Epoch 00012: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 238s 584ms/sample - loss: 0.2446 - dice_coef: 0.5305 - acc: 0.4908 - val_loss: 0.5087 - val_dice_coef: 0.0000e+00 - val_acc: 0.3473\n",
      "Epoch 13/100\n",
      "384/408 [===========================>..] - ETA: 3:41 - loss: 0.2372 - dice_coef: 0.6439 - acc: 0.518 - ETA: 3:23 - loss: 0.2444 - dice_coef: 0.6120 - acc: 0.510 - ETA: 3:08 - loss: 0.2110 - dice_coef: 0.5812 - acc: 0.483 - ETA: 2:48 - loss: 0.1876 - dice_coef: 0.6357 - acc: 0.489 - ETA: 2:29 - loss: 0.1893 - dice_coef: 0.6387 - acc: 0.490 - ETA: 2:11 - loss: 0.2133 - dice_coef: 0.6102 - acc: 0.494 - ETA: 1:51 - loss: 0.2210 - dice_coef: 0.5939 - acc: 0.491 - ETA: 1:32 - loss: 0.2366 - dice_coef: 0.5682 - acc: 0.485 - ETA: 1:13 - loss: 0.2356 - dice_coef: 0.5698 - acc: 0.485 - ETA: 53s - loss: 0.2237 - dice_coef: 0.5893 - acc: 0.485 - ETA: 34s - loss: 0.2318 - dice_coef: 0.5749 - acc: 0.48 - ETA: 14s - loss: 0.2396 - dice_coef: 0.5584 - acc: 0.4856\n",
      "Epoch 00013: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 258s 633ms/sample - loss: 0.2441 - dice_coef: 0.5562 - acc: 0.4882 - val_loss: 0.4973 - val_dice_coef: 2.2912e-06 - val_acc: 0.3496\n",
      "Epoch 14/100\n",
      "384/408 [===========================>..] - ETA: 3:43 - loss: 0.3638 - dice_coef: 0.3756 - acc: 0.535 - ETA: 3:31 - loss: 0.3025 - dice_coef: 0.4860 - acc: 0.527 - ETA: 3:11 - loss: 0.2851 - dice_coef: 0.5263 - acc: 0.511 - ETA: 2:50 - loss: 0.2830 - dice_coef: 0.5236 - acc: 0.497 - ETA: 2:32 - loss: 0.3060 - dice_coef: 0.5034 - acc: 0.498 - ETA: 2:12 - loss: 0.2825 - dice_coef: 0.5375 - acc: 0.495 - ETA: 1:52 - loss: 0.2520 - dice_coef: 0.5433 - acc: 0.485 - ETA: 1:34 - loss: 0.2414 - dice_coef: 0.5473 - acc: 0.481 - ETA: 1:14 - loss: 0.2433 - dice_coef: 0.5490 - acc: 0.487 - ETA: 53s - loss: 0.2504 - dice_coef: 0.5368 - acc: 0.493 - ETA: 34s - loss: 0.2463 - dice_coef: 0.5240 - acc: 0.48 - ETA: 14s - loss: 0.2393 - dice_coef: 0.5385 - acc: 0.4884\n",
      "Epoch 00014: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 255s 625ms/sample - loss: 0.2410 - dice_coef: 0.5354 - acc: 0.4866 - val_loss: 0.4824 - val_dice_coef: 1.3468e-04 - val_acc: 0.3536\n",
      "Epoch 15/100\n",
      "384/408 [===========================>..] - ETA: 3:40 - loss: 0.2444 - dice_coef: 0.5401 - acc: 0.468 - ETA: 3:15 - loss: 0.2075 - dice_coef: 0.6214 - acc: 0.470 - ETA: 2:55 - loss: 0.1850 - dice_coef: 0.6439 - acc: 0.470 - ETA: 2:36 - loss: 0.1958 - dice_coef: 0.6332 - acc: 0.482 - ETA: 2:19 - loss: 0.1839 - dice_coef: 0.6522 - acc: 0.481 - ETA: 2:01 - loss: 0.1849 - dice_coef: 0.6542 - acc: 0.480 - ETA: 1:42 - loss: 0.1860 - dice_coef: 0.6399 - acc: 0.475 - ETA: 1:26 - loss: 0.1888 - dice_coef: 0.6360 - acc: 0.475 - ETA: 1:08 - loss: 0.1994 - dice_coef: 0.6266 - acc: 0.478 - ETA: 49s - loss: 0.2191 - dice_coef: 0.5911 - acc: 0.479 - ETA: 31s - loss: 0.2244 - dice_coef: 0.5825 - acc: 0.48 - ETA: 13s - loss: 0.2290 - dice_coef: 0.5728 - acc: 0.4868\n",
      "Epoch 00015: val_loss did not improve from 0.40051\n",
      "408/408 [==============================] - 242s 593ms/sample - loss: 0.2336 - dice_coef: 0.5689 - acc: 0.4879 - val_loss: 0.4661 - val_dice_coef: 0.0012 - val_acc: 0.3591\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=callbacks,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-unet-basic_tf2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_train = model.predict(X_train, verbose=1)\n",
    "preds_val = model.predict(X_valid, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix])\n",
    "   \n",
    "    ax[0].set_title('Image')\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze())\n",
    "    ax[1].set_title('Mask')\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "   \n",
    "    ax[2].set_title('Mask Predicted')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "for i in range(0,10):\n",
    "    plot_sample(X_train, y_train, preds_train, preds_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if valid data looks all right\n",
    "plot_sample(X_valid, y_valid, preds_val, preds_val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = os.path.join( os.getcwd(), 'input',  'test')\n",
    "X_test, y_test = get_data(path_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_test, y_test, preds_test, preds_test_t, ix=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_big = os.path.join(os.getcwd(), 'input', 'big')\n",
    "X_big, y_big = get_data(path_big, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_big = model.predict(X_big, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_big_t = (preds_big > 0.5).astype(np.uint8)\n",
    "plot_sample(X_big, y_big, preds_big, preds_big_t, ix=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_big[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_sample(X_test, y_test, preds_test, preds_test_t, ix=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 7832."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir log\\s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
