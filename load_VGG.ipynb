{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_vgg(sess, vgg_path):\n  \n  # load the model and weights\n  model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n\n  # Get Tensors to be returned from graph\n  graph = tf.get_default_graph()\n  image_input = graph.get_tensor_by_name('image_input:0')\n  keep_prob = graph.get_tensor_by_name('keep_prob:0')\n  layer3 = graph.get_tensor_by_name('layer3_out:0')\n  layer4 = graph.get_tensor_by_name('layer4_out:0')\n  layer7 = graph.get_tensor_by_name('layer7_out:0')\n\n  return image_input, keep_prob, layer3, layer4, layer7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_vgg(sess, vgg_path):\n  \n  # load the model and weights\n  model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n\n  # Get Tensors to be returned from graph\n  graph = tf.get_default_graph()\n  image_input = graph.get_tensor_by_name('image_input:0')\n  keep_prob = graph.get_tensor_by_name('keep_prob:0')\n  layer3 = graph.get_tensor_by_name('layer3_out:0')\n  layer4 = graph.get_tensor_by_name('layer4_out:0')\n  layer7 = graph.get_tensor_by_name('layer7_out:0')\n\n  return image_input, keep_prob, layer3, layer4, layer7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n   \n    # Use a shorter variable name for simplicity\n    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n\n    # Apply 1x1 convolution in place of fully connected layer\n    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n\n    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n    fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\")\n\n    # Add a skip connection between current final layer fcn8 and 4th layer\n    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n\n    # Upsample again\n    fcn10 = tf.layers.conv2d_transpose(fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\")\n\n    # Add skip connection\n    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n\n    # Upsample again\n    fcn11 = tf.layers.conv2d_transpose(fcn10_skip_connected, filters=num_classes,\n    kernel_size=16, strides=(8, 8), padding='SAME', name=\"fcn11\")\n\n    return fcn11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n  \n  # Reshape 4D tensors to 2D, each row represents a pixel, each column a class\n  logits = tf.reshape(nn_last_layer, (-1, num_classes), name=\"fcn_logits\")\n  correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n\n  # Calculate distance from actual labels using cross entropy\n  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n  # Take mean for total loss\n  loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n\n  # The model implements this operation to find the weights/parameters that would yield correct pixel labels\n  train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name=\"fcn_train_op\")\n\n  return logits, train_op, loss_op","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n             cross_entropy_loss, input_image,\n             correct_label, keep_prob, learning_rate):\n\n  keep_prob_value = 0.5\n  learning_rate_value = 0.001\n  for epoch in range(epochs):\n      # Create function to get batches\n      total_loss = 0\n      for X_batch, gt_batch in get_batches_fn(batch_size):\n\n          loss, _ = sess.run([cross_entropy_loss, train_op],\n          feed_dict={input_image: X_batch, correct_label: gt_batch,\n          keep_prob: keep_prob_value, learning_rate:learning_rate_value})\n\n          total_loss += loss;\n\n      print(\"EPOCH {} ...\".format(epoch + 1))\n      print(\"Loss = {:.3f}\".format(total_loss))\n      print()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n   \n    # Use a shorter variable name for simplicity\n    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n\n    # Apply 1x1 convolution in place of fully connected layer\n    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n\n    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n    fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\")\n\n    # Add a skip connection between current final layer fcn8 and 4th layer\n    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n\n    # Upsample again\n    fcn10 = tf.layers.conv2d_transpose(fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\")\n\n    # Add skip connection\n    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n\n    # Upsample again\n    fcn11 = tf.layers.conv2d_transpose(fcn10_skip_connected, filters=num_classes,\n    kernel_size=16, strides=(8, 8), padding='SAME', name=\"fcn11\")\n\n    return fcn11\n\ndef optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n  \n  # Reshape 4D tensors to 2D, each row represents a pixel, each column a class\n  logits = tf.reshape(nn_last_layer, (-1, num_classes), name=\"fcn_logits\")\n  correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n\n  # Calculate distance from actual labels using cross entropy\n  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n  # Take mean for total loss\n  loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n\n  # The model implements this operation to find the weights/parameters that would yield correct pixel labels\n  train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name=\"fcn_train_op\")\n\n  return logits, train_op, loss_op\n\ndef train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n             cross_entropy_loss, input_image,\n             correct_label, keep_prob, learning_rate):\n\n  keep_prob_value = 0.5\n  learning_rate_value = 0.001\n  for epoch in range(epochs):\n      # Create function to get batches\n      total_loss = 0\n      for X_batch, gt_batch in get_batches_fn(batch_size):\n\n          loss, _ = sess.run([cross_entropy_loss, train_op],\n          feed_dict={input_image: X_batch, correct_label: gt_batch,\n          keep_prob: keep_prob_value, learning_rate:learning_rate_value})\n\n          total_loss += loss;\n\n      print(\"EPOCH {} ...\".format(epoch + 1))\n      print(\"Loss = {:.3f}\".format(total_loss))\n      print()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}